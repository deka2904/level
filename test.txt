import pandas as pd
import seaborn as sns
import numpy as np
import marplotlib.pyplot as plt


df = pd.read_csv(파일 경로)
● aidu 내 data 폴더에 들어 있을 경우 (데이터관리에서 파일 업로드)
● aidu 메인에 파일이 있을 경우 -> 파일명만 기입

# 데이터 전체 구조 보기
df 

# 데이터 전체 컬럼명 보기
df.columns

# 데이터 상위 5행 출력
df.head()

# 데이터 하위 5행 출력
df.tail()

# 데이터 정보확인
df.info()

#데이터 (행, 열) 크기 확인
df.shape

# 데이터 통계 보기
df.describe()

# 중앙값(숫자형)
df[‘컬럼명’].median()
df.median()

# 컬럼 내 각각의 값 분포
*특적컬럼 : df[‘컬럼명’].value_counts()
*전체걸럼 : [df[c].value_counts() for c in df]

# 특정 컬럼 내 각각의 값 분표 비율
df[‘컬럼명’].value_counts(normalize=True)

# 특정 컴럼 내 유일 한 값 확인
df[‘컬럼명’].unique()
# 데이터 결측치 확인
df.isnull().sum()

# 데이터 타입 확인 
df.dtypes

# 두 변수간 상관관계 분석
df.corr()

# 레이블 선택
y = df[‘컬럼명’]

# 차트 그리기(matplotlib)
import matplotlib.pyplot as plt

plt.rc(‘font’, family=‘폰트명’)        # 한글폰트 적용
plt.plot(history.history[‘acc’])       # 출력 그래프 데이터
plt.plot(history.history[‘val_acc’])   # 출력 그래프 데이터
plt.title(‘Accuracy’)      # 차트 타이틀
plt.xlabel(‘Epochs’)      # x축 라벨
plt.ylabel(‘Acc’)          # Y축 라벨
plt.legend([‘acc’,‘’val_acc’])    # 범례
plt.show()             # 그래프 보이기

# 산점도 그리기
plt.scatter(x,y)

# 막대 그래프 그리기
plt.bar(x,y)

# 히스토그램 그리기 
plt.hist(values)
(자세한 내용은 -> https://wikidocs.net/book/5011)

# 차트 그리기 (seaborn) - heatmap
import seaborn as sns
sns.heatmap(df.corr(), annot=True)

# 차트 그리기(seaborn) - pairplot
sns.pairplot(data=df, 
            x_vars=[‘bbb’,‘ccc’,‘ddd’]
            y_vars = [‘aaa’])

# 특정 컬럼 삭제
df1 = df.drop(columns=[‘컬럼명’, ‘컬럼명’])
df1 = df.drop([‘컬럼명’, ‘컬럼명’], axis=1)

-> axis = 0 (행) / axis = 1 (열)

# 값 변경
*특정컬럼:
df1[‘컬럼명’].replace(‘변경전값’,‘변경후값’,inplace=True)

*전체컬럼:
df1.replace(‘변경전값’, ‘변경후값’, inplace=True)

# 특정 값이 있는 행만 가져오기
df1[df1[‘컬럼명’]==‘비교값’]

# 특정 값의 개수 확인
(df[‘컬러명’] == ‘비교값’).sum()

# 전체 값의 개수 확인 
df1.apply(lambda x:x.isin([‘비교값’]).sum())

# Null값 처리
df1[‘컬럼명’].fillna(‘변경값’, inplace=True)
df1[‘컬럼명’].replace(np.nan, ‘변경값’, inplace=True)
# 이상치란? 
데이터 상의 다른값들의 분포와 비굣 비정상적으로 떨어져 있는 데이터 값

# 이상치 데이터 확인
sns.boxplot(x=‘Churn’, y=‘MonthlyCharges’, data=df)
sns.scatterplot(x=‘Churn’, y=‘MonthlyCharges’, data=df)

#데이터 복사
df1_copy = df.copy()

#데이터 타입 변경
df1[‘컬럼명’] = df1[‘컬럼명’].astype(타입)

# 특정 데이터 타입의 컬럼 선택
c = df1.select_dtypes(include=“데이터타입”)

# 문자를 숫자로 변경(라벨인코딩)
from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
df1[“컬럼명”] = le.fit_transform(df1[“컬럼명”])

참고) scikit-learn에서는 문자열 값을 입력으로 허용하지 않아 숫자형으로 변경 필요
선형회귀에서는 큰수가 가중치가 놓아지는 문제가 발생되어 적용하면 안됨
(의사결정 트리와 같은 트리 계열은 가능)

# 문자를 숫자로 변경(원-핫 인코딩)
pd.get_dummies(데이터프레임 또는 열)
pd.get_dummies(데이터프레임, columns=[‘컬럼명’])
참고) 원-핫 인코딩에서 결측값은 기본적으로 제외됨

*결측값을 포함하여 원-핫 인코딩 필요할 경우
pd.get_dummies(df[‘name’], dummy_na=True)

*첫번째 카테고리(인코딩 데이터) 삭제
pd.get_dummies(df[‘name’], drop_first = True)
참고) 나머지 데이터로 유추 할 수 있기 떄문에 메모리 절약 가능

# Feature(X) / Target(Y) 분리
X = df1.drop(columns=[‘Y가 있는 컬럼명’].values
Y = df1[‘Y가 있는 컬럼명’].values
참고) 머신러닝을 위해 values함수를 사용하여 array형태의 값만 추출(헤더정보 제외)

# 학습데이터(train set)와 검증데이터(test set)로 분리
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, stratify=Y, random_state=0)

옵션값)
test_size = 검증데이터(test set) 비율(0~1 값)
shuffle = 데이터 분리전 데이터를 섞을지 여부(default=True)
stratify = 원래 데이터(Y)의 분포 비율 유지
random_state = 데이터를 섞을 때 사용할 시드 값

# 데이터 스케일링
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandarScaler

scaler = MinMaxScaler()  #정규화: 최대값 1, 최소값 0 
scaler = StandarScaler()  #표준화: 평균값 0, 표준편차 1

X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)



fit : 정규화. 평균과 표준편차를 계산하는 작업
fit_transform : train set에만 사용
transform : train set으로부터 학습된 평균과 표준편차 값을 test set에 적용
            test set에도 fit 적용 시

# 선형회귀
from sklearn.linear_model import LinearRegression
from sklearn.metrics import accuracy_score

model = LinearRegression()
model.fit(X_train, Y_train)
predicted = model.predict(X_test)
accuracy = accuracy_score(Y_test, predicted)

# 로지스틱회귀
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

model = LogisticRegression()
model.fit(X_train, Y_train)
predicted = model.predict(X_test)
accuracy = accuracy_score(Y_test, predicted)

# 의사결정트리
from sklearn.tree import DecisionTreeClassifier

model = DecisionTreeClassifier(max_depth = 10, random_state=42)
model.fit(X_train, Y_train)
model.score(X_test, Y_test)

# 랜덤포레스트
from sklearn.ensemble import RandomForestCassifier 
from sklearn.metrics import accuracy_score

model = RandomForestCassifier (n_estimators=20, max_depth=5, random_state = 42)
model.fit(X_train, Y_train)
predicted = model.predict(X_test)
accuracy = accuracy_score(Y_test, predicted)

# 텐서플로우를 활용한 딥러닝
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Activation, Dropout
from tensorflow.keras.call.backs import EarlyStopping, ModelCheckpoint

batch_size = 8 -> 한번에 처리할 데이터량 (총 데이터가 100개면 8개씩 쪼개서 학습)
Epochs = 20 -> 학습을 진행할 횟수(총 데이터가 100개면 100개 학습이 다 끝나면 1 epoch)

# 텐서플로우 학습모델 만들기
model = Sequential()  # Sequential :원하는 레이어를 순차적으로 쌓는 방식의 모델
model.add(Dense(units=16, input_shape=(10,),activation=’relu’)) # 첫 번째 레이어에는 입력데이터의 shape(열의 개수) 반드시 명시 필요

Model.add(Dropout(0.2)) # Dropout 과접합(오버피팅)방지를 위한 함수
Model.add(Dense(8, activation=’relu’)) # second hidden layer
Model.add(Dense(1, activation=‘sigmoid’)) # 최종 Y의 라벨 개수로 레이어 합치기

# Dense는 input과 output을 연결해 주는 레이어
# Dense units : 출력값의 크기(뉴런의 수)# Dense activation : 활성화 함수 – 최종 출력 결과를 다음 레이어로 보낼지 결정# Dropout : Traininf Data에서 학습이 덜 될 수 있지만, 일반화 능력을 키워 Test Data에 대한 예측율을 높이는 방법
#이진분류
model.add(Dense(1, activation=‘sigmoid’))
Model.compile(optimizer=“adam”, loss=“binary_crossentropy”, metrics=[‘accuracy’]) # loss: 손실함수, metrics: 평가기준
참고) 손실함수 : 실제 결과와 예측결과의 차이를 비교하는 함수

#다중분류
Model.add(Dense(최종output 레이어 개수, activation=“softmax”))
model.compile(optimizer=“adam”, loss=“categorical_crossentropy”, metrics=[‘accuracy’]) (Y : 원핫인코딩 된 경우)
model.compile(optimizer=“adam”, loss=“sparse_categorical_crossentropy”, metrics=[‘accuracy’]) (Y : 원핫인코딩 안된 경우)

#예측
model.add(Dense(1))
model.compile(optimizer=“adam”, loss=“mse”, metrics=[‘mse’,‘mae’]

mae : Mean Absolute Error -> 예측값과 결과값의 차이의 절대값을 전부 더하고, 개수로 나누어 평균을 낸것 
mse : Mean Square Error -> 예측값과 결과값의 차이를 제곱하여 전부 더하고 개수로 나누어 평균을 낸 것 

# call back : 개발자가 원하는 동작을 하도록 해주는 기능
# val_loss(출력값과 정답의 차이) 값이 4epochs 안에 개선되지 않으면 중지
es = EarlyStopping(monitor=‘val_loss’, patience=4, mode=‘min’, verbose=1)
# val_loss값이 개선되면 best_mode.h5로 저장
mc = ModelCheckpoint(“best_model.h5”, monitor=‘val_loss’, mode=‘min’, verbose=1, save_best_only=True)

# 학습하기
history = model.fit(X_train, Y_train,
                   batch_size = batch_size,
                   epochs = Epochs,
                   verbose = 1,
                   validation_data = (X_test,Y_test),
                   callback=[es, mx])
#학습 그래프 그리기 
# Accuracy 그래프 그리기
plt.plot(history.history[‘accuracy’], label=‘acc’)
plt.plot(history.history[‘val_accuracy’], label=‘val_acc’)
plt.title(‘Accuracy’)
plt.xlabel(“Epochs”)
plt.ylabel(“Acc”)
plt.legend([“accuracy”,“val_accuracy”])
plt.show()

# Loss 그래프 그리기
plt.plot(history.history[‘loss’], label=‘train_loss’)
plt.plot(history.history[‘val_loss’], label=‘validation loss’)
plt.title(‘Loss’)
plt.xlabel(“Epochs”)
plt.ylabel(“Loss”)
plt.legend([“loss”,“val_loss”])
plt.show()

-----------------------------------------------------------------------
Confusion Matrix(분류결과표)
Precision(정밀도) -> 모델이 True로 분류한 것 중 실제 True 비율
F1 Score -> Precision과 Recall의 가중조화편균 정밀도와 재현율이 어느 한쪽으로 치우치지 않을 때 상대적으로 높은 값을 가짐
Recall(재현율) -> 실제 정답이 True 중 모델이 True로 예측한 비율
Accuracy(정확도) -> 실제 정답 True를 모델이 True한 것 + 실제 정답 False를 모델이 False 한것의 비율


# 성능 평가하기
# 분류모델의 성능평가 구현
y_pred = forset.predict(X_test) # 데이터 예측

#confusion Matrix
from sklearn.metrics import confusion_matrix
cm = confusion_martrix(y_test, y_pred)

#precision
from sklearn.metrics import precision_score
ps = precision_score(y_test, y_pred, pos_label = 1)

#Recall
from sklearn.metrics import recall_score
rs = recall_score(y_test, y_pred, pos_label=1)

#F1 score
from sklearn.metrics import f1_score
fs = f1_score(y_test, y_pred, pos_label=1)

#Accuracy
from sklearn.metrics import accuracy_score
accs = accuracy_score(y_test,y_pred)

#Classification Report
from sklearn.metrics import classification_report
cr = classification_report(y_test, y_pred, target_names=[‘class0’,‘class1’])
